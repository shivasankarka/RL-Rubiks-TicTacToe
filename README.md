# Project README

## Overview

Welcome to my project! This repository contains my experiments and implementations inspired by AlphaZero. The primary goal of this project is to explore and learn reinforcement learning and deep learning techniques through practical applications.

## Project Components

### 1. Tic-Tac-Toe with MCTS and Neural Networks

In this part of the project, I am training a neural network using Monte Carlo Tree Search (MCTS) to play Tic-Tac-Toe. The objective is to create an NN that can learn and improve its gameplay over time by simulating numerous game scenarios and making optimal decisions based on the outcomes.

### 2. Rubik's Cube Solver with Neural Networks and A* Search

The second part of the project focuses on solving the Rubik's Cube. Here, I am training a neural network to estimate the number of moves required to solve the Rubik's Cube from any given state. This neural network acts as a heuristic for the A* search algorithm, guiding it towards the most efficient solution path. This approach is based on a research paper that I am attempting to reproduce.

## Learning Objectives

The main purpose of these projects is to deepen my understanding of reinforcement learning and deep learning. By working on these challenging problems, I aim to gain hands-on experience with different techniques and improve my problem-solving skills.

## License

This project is licensed under the MIT License. See the LICENSE file for more details.

## Acknowledgements

I would like to thank the authors of the original AlphaZero paper and the Rubik's Cube heuristic paper for their inspiring work.